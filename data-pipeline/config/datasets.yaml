# Dataset sources for Iikshana data pipeline
# Many emotion/speech datasets require registration; URLs below are examples or public mirrors where available.

emotion_datasets:
  RAVDESS:
    # Ryerson Audio-Visual Database of Emotional Speech and Song
    # Register: https://zenodo.org/record/1188976
    url: "https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip"
    checksum: null  # set after first download for validation
    emotion_classes: 8  # neutral, calm, happy, sad, angry, fearful, disgust, surprised
    format: wav
  IEMOCAP:
    # USC IEMOCAP (license required)
    url: null  # obtained after registration
    emotion_classes: 5  # neutral, happiness, sadness, anger, frustrated
    format: wav
  CREMA-D:
    # Crema-D (license required)
    url: null
    emotion_classes: 6
    format: wav
  MELD:
    # Multimodal EmotionLines Dataset
    url: null #"https://github.com/declare-lab/MELD/archive/refs/heads/master.zip"
    emotion_classes: 7
    format: wav
  TESS:
    # Toronto Emotional Speech Set. Add direct ZIP URL after manual download from:
    # https://borealisdata.ca/dataset.xhtml?persistentId=doi%3A10.5683%2FSP2%2FE8H2MF
    url: null
    emotion_classes: 7
    format: wav
  SAVEE:
    url: null
    emotion_classes: 7
    format: wav
  EMO-DB:
    # Berlin EMO-DB
    url: null
    emotion_classes: 7
    format: wav

multilingual_speech:
  common_voice:
    # Mozilla Common Voice (subset; full via Hugging Face datasets)
    url: "https://huggingface.co/datasets/mozilla-foundation/common_voice_17_0"
    format: mp3
  voxpopuli:
    url: null
  librispeech:
    url: null
    checksum: null

# Pipeline settings
# include_video: true enables .mp4/.mkv etc. (e.g. MELD); requires ffmpeg installed
preprocessing:
  target_sr: 16000
  mono: true
  normalize_loudness: true
  trim_silence: true
  include_video: true

splits:
  dev: 0.20
  test: 0.70
  holdout: 0.10

validation:
  expected_sr: 16000
  min_duration_sec: 0.5
  max_duration_sec: 30.0
  allowed_emotion_labels:
    RAVDESS: ["neutral", "calm", "happy", "sad", "angry", "fearful", "disgust", "surprised"]
    IEMOCAP: ["neutral", "happiness", "sadness", "anger", "frustrated"]

# Optional: anomaly check thresholds (defaults used if missing)
anomaly_checks:
  max_class_ratio: 0.80   # flag if any emotion > 80%
  min_class_ratio: 0.01   # flag if any emotion < 5%
  fail_on_schema_failures: true   # treat validation failures as anomalies
  min_files_per_split: 1   # require at least this many WAVs per dev/test/holdout
  max_out_of_range_ratio: 0.2   # flag if fraction of files outside duration range exceeds this
  min_dataset_ratio: 0.01   # flag if any dataset < 1% of total (multi-dataset)
  max_dataset_ratio: 0.95   # flag if any dataset > 95% of total (multi-dataset)
