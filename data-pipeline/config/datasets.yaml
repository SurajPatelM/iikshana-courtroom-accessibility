# Dataset sources for Iikshana data pipeline
# Many emotion/speech datasets require registration; URLs below are examples or public mirrors where available.

emotion_datasets:
  RAVDESS:
    # Ryerson Audio-Visual Database of Emotional Speech and Song
    # Register: https://zenodo.org/record/1188976
    url: "https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip"
    checksum: null  # set after first download for validation
    emotion_classes: 8  # neutral, calm, happy, sad, angry, fearful, disgust, surprised
    format: wav
  IEMOCAP:
    # USC IEMOCAP (license required)
    url: null  # obtained after registration
    emotion_classes: 5  # neutral, happiness, sadness, anger, frustrated
    format: wav
  CREMA-D:
    # Crema-D (license required)
    url: null
    emotion_classes: 6
    format: wav
  MELD:
    # Multimodal EmotionLines Dataset
    url: "https://github.com/declare-lab/MELD/archive/refs/heads/master.zip"
    emotion_classes: 7
    format: wav
  TESS:
    # Toronto Emotional Speech Set
    url: null  # available from U of T
    emotion_classes: 7
    format: wav
  SAVEE:
    url: null
    emotion_classes: 7
    format: wav
  EMO-DB:
    # Berlin EMO-DB
    url: null
    emotion_classes: 7
    format: wav

multilingual_speech:
  common_voice:
    # Mozilla Common Voice (subset; full via Hugging Face datasets)
    url: "https://huggingface.co/datasets/mozilla-foundation/common_voice_17_0"
    format: mp3
  voxpopuli:
    url: null
  librispeech:
    url: null

# Pipeline settings
preprocessing:
  target_sr: 16000
  mono: true
  normalize_loudness: true
  trim_silence: true

splits:
  dev: 0.20
  test: 0.70
  holdout: 0.10

validation:
  expected_sr: 16000
  min_duration_sec: 0.5
  max_duration_sec: 30.0
  allowed_emotion_labels:
    RAVDESS: ["neutral", "calm", "happy", "sad", "angry", "fearful", "disgust", "surprised"]
    IEMOCAP: ["neutral", "happiness", "sadness", "anger", "frustrated"]
